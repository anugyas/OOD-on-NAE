{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code taken and modified from https://github.com/hendrycks/natural-adv-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/hendrycks/natural-adv-examples/blob/master/calibration_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as sk\n",
    "recall_level_default = 0.95\n",
    "\n",
    "def stable_cumsum(arr, rtol=1e-05, atol=1e-08):\n",
    "    \"\"\"Use high precision for cumsum and check that final value matches sum\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : array-like\n",
    "        To be cumulatively summed as flat\n",
    "    rtol : float\n",
    "        Relative tolerance, see ``np.allclose``\n",
    "    atol : float\n",
    "        Absolute tolerance, see ``np.allclose``\n",
    "\n",
    "    Credits: https://github.com/wetliu/energy_ood/blob/7d31247d980b5337c519a61402d35141f5ec6289/utils/display_results.py#L7\n",
    "    \"\"\"\n",
    "    out = np.cumsum(arr, dtype=np.float64)\n",
    "    expected = np.sum(arr, dtype=np.float64)\n",
    "    if not np.allclose(out[-1], expected, rtol=rtol, atol=atol):\n",
    "        raise RuntimeError('cumsum was found to be unstable: '\n",
    "                           'its last element does not correspond to sum')\n",
    "    return out\n",
    "\n",
    "def calib_err(confidence, correct, p='2', beta=100):\n",
    "    # beta is target bin size\n",
    "    idxs = np.argsort(confidence)\n",
    "    confidence = confidence[idxs]\n",
    "    correct = correct[idxs]\n",
    "    bins = [[i * beta, (i + 1) * beta] for i in range(len(confidence) // beta)]\n",
    "    bins[-1] = [bins[-1][0], len(confidence)]\n",
    "\n",
    "    cerr = 0\n",
    "    total_examples = len(confidence)\n",
    "    for i in range(len(bins) - 1):\n",
    "        bin_confidence = confidence[bins[i][0]:bins[i][1]]\n",
    "        bin_correct = correct[bins[i][0]:bins[i][1]]\n",
    "        num_examples_in_bin = len(bin_confidence)\n",
    "\n",
    "        if num_examples_in_bin > 0:\n",
    "            difference = np.abs(np.nanmean(bin_confidence) - np.nanmean(bin_correct))\n",
    "\n",
    "            if p == '2':\n",
    "                cerr += num_examples_in_bin / total_examples * np.square(difference)\n",
    "            elif p == '1':\n",
    "                cerr += num_examples_in_bin / total_examples * difference\n",
    "            elif p == 'infty' or p == 'infinity' or p == 'max':\n",
    "                cerr = np.maximum(cerr, difference)\n",
    "            else:\n",
    "                assert False, \"p must be '1', '2', or 'infty'\"\n",
    "\n",
    "    if p == '2':\n",
    "        cerr = np.sqrt(cerr)\n",
    "\n",
    "    return cerr\n",
    "\n",
    "\n",
    "def aurra(confidence, correct):\n",
    "    conf_ranks = np.argsort(confidence)[::-1]  # indices from greatest to least confidence\n",
    "    rra_curve = np.cumsum(np.asarray(correct)[conf_ranks])\n",
    "    rra_curve = rra_curve / np.arange(1, len(rra_curve) + 1)  # accuracy at each response rate\n",
    "    return np.mean(rra_curve)\n",
    "\n",
    "\n",
    "def soft_f1(confidence, correct):\n",
    "    wrong = 1 - correct\n",
    "\n",
    "    # # the incorrectly classified samples are our interest\n",
    "    # # so they make the positive class\n",
    "    # tp_soft = np.sum((1 - confidence) * wrong)\n",
    "    # fp_soft = np.sum((1 - confidence) * correct)\n",
    "    # fn_soft = np.sum(confidence * wrong)\n",
    "\n",
    "    # return 2 * tp_soft / (2 * tp_soft + fn_soft + fp_soft)\n",
    "    return 2 * ((1 - confidence) * wrong).sum()/(1 - confidence + wrong).sum()\n",
    "\n",
    "\n",
    "def tune_temp(logits, labels, binary_search=True, lower=0.2, upper=5.0, eps=0.0001):\n",
    "    logits = np.array(logits)\n",
    "\n",
    "    if binary_search:\n",
    "        import torch\n",
    "        import torch.nn.functional as F\n",
    "\n",
    "        logits = torch.FloatTensor(logits)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        t_guess = torch.FloatTensor([0.5*(lower + upper)]).requires_grad_()\n",
    "\n",
    "        while upper - lower > eps:\n",
    "            if torch.autograd.grad(F.cross_entropy(logits / t_guess, labels), t_guess)[0] > 0:\n",
    "                upper = 0.5 * (lower + upper)\n",
    "            else:\n",
    "                lower = 0.5 * (lower + upper)\n",
    "            t_guess = t_guess * 0 + 0.5 * (lower + upper)\n",
    "\n",
    "        t = min([lower, 0.5 * (lower + upper), upper], key=lambda x: float(F.cross_entropy(logits / x, labels)))\n",
    "    else:\n",
    "        import cvxpy as cx\n",
    "\n",
    "        set_size = np.array(logits).shape[0]\n",
    "\n",
    "        t = cx.Variable()\n",
    "\n",
    "        expr = sum((cx.Minimize(cx.log_sum_exp(logits[i, :] * t) - logits[i, labels[i]] * t)\n",
    "                    for i in range(set_size)))\n",
    "        p = cx.Problem(expr, [lower <= t, t <= upper])\n",
    "\n",
    "        p.solve()   # p.solve(solver=cx.SCS)\n",
    "        t = 1 / t.value\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def print_measures(rms, aurra_metric, mad, sf1, method_name='Baseline'):\n",
    "    print('\\t\\t\\t\\t\\t\\t\\t' + method_name)\n",
    "    print('RMS Calib Error (%): \\t\\t{:.2f}'.format(100 * rms))\n",
    "    print('AURRA (%): \\t\\t\\t{:.2f}'.format(100 * aurra))\n",
    "    # print('MAD Calib Error (%): \\t\\t{:.2f}'.format(100 * mad))\n",
    "    # print('Soft F1 Score (%):   \\t\\t{:.2f}'.format(100 * sf1))\n",
    "\n",
    "\n",
    "def show_calibration_results(confidence, correct, method_name='Baseline'):\n",
    "\n",
    "    print('\\t\\t\\t\\t' + method_name)\n",
    "    print('RMS Calib Error (%): \\t\\t{:.2f}'.format(\n",
    "        100 * calib_err(confidence, correct, p='2')))\n",
    "\n",
    "    print('AURRA (%): \\t\\t\\t{:.2f}'.format(\n",
    "        100 * aurra(confidence, correct)))\n",
    "\n",
    "    # print('MAD Calib Error (%): \\t\\t{:.2f}'.format(\n",
    "    #     100 * calib_err(confidence, correct, p='1')))\n",
    "\n",
    "    # print('Soft F1-Score (%): \\t\\t{:.2f}'.format(\n",
    "    #     100 * soft_f1(confidence, correct)))\n",
    "\n",
    "def fpr_and_fdr_at_recall(y_true, y_score, recall_level=recall_level_default, pos_label=None):\n",
    "    classes = np.unique(y_true)\n",
    "    if (pos_label is None and\n",
    "            not (np.array_equal(classes, [0, 1]) or\n",
    "                     np.array_equal(classes, [-1, 1]) or\n",
    "                     np.array_equal(classes, [0]) or\n",
    "                     np.array_equal(classes, [-1]) or\n",
    "                     np.array_equal(classes, [1]))):\n",
    "        raise ValueError(\"Data is not binary and pos_label is not specified\")\n",
    "    elif pos_label is None:\n",
    "        pos_label = 1.\n",
    "\n",
    "    # make y_true a boolean vector\n",
    "    y_true = (y_true == pos_label)\n",
    "\n",
    "    # sort scores and corresponding truth values\n",
    "    desc_score_indices = np.argsort(y_score, kind=\"mergesort\")[::-1]\n",
    "    y_score = y_score[desc_score_indices]\n",
    "    y_true = y_true[desc_score_indices]\n",
    "\n",
    "    # y_score typically has many tied values. Here we extract\n",
    "    # the indices associated with the distinct values. We also\n",
    "    # concatenate a value for the end of the curve.\n",
    "    distinct_value_indices = np.where(np.diff(y_score))[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n",
    "\n",
    "    # accumulate the true positives with decreasing threshold\n",
    "    tps = stable_cumsum(y_true)[threshold_idxs]\n",
    "    fps = 1 + threshold_idxs - tps      # add one because of zero-based indexing\n",
    "\n",
    "    thresholds = y_score[threshold_idxs]\n",
    "\n",
    "    recall = tps / tps[-1]\n",
    "\n",
    "    last_ind = tps.searchsorted(tps[-1])\n",
    "    sl = slice(last_ind, None, -1)      # [last_ind::-1]\n",
    "    recall, fps, tps, thresholds = np.r_[recall[sl], 1], np.r_[fps[sl], 0], np.r_[tps[sl], 0], thresholds[sl]\n",
    "\n",
    "    cutoff = np.argmin(np.abs(recall - recall_level))\n",
    "\n",
    "    return fps[cutoff] / (np.sum(np.logical_not(y_true)))   # , fps[cutoff]/(fps[cutoff] + tps[cutoff])\n",
    "\n",
    "def get_measures(_pos, _neg, recall_level=recall_level_default):\n",
    "    pos = np.array(_pos[:]).reshape((-1, 1))\n",
    "    neg = np.array(_neg[:]).reshape((-1, 1))\n",
    "    examples = np.squeeze(np.vstack((pos, neg)))\n",
    "    labels = np.zeros(len(examples), dtype=np.int32)\n",
    "    labels[:len(pos)] += 1\n",
    "\n",
    "    auroc = sk.roc_auc_score(labels, examples)\n",
    "    aupr = sk.average_precision_score(labels, examples)\n",
    "    fpr = fpr_and_fdr_at_recall(labels, examples, recall_level)\n",
    "\n",
    "    return auroc, aupr, fpr\n",
    "\n",
    "\n",
    "def print_measures_old(auroc, aupr, fpr, method_name='Ours', recall_level=recall_level_default):\n",
    "    print('\\t\\t\\t' + method_name)\n",
    "    print('FPR{:d}:\\t{:.2f}'.format(int(100 * recall_level), 100 * fpr))\n",
    "    print('AUROC: \\t{:.2f}'.format(100 * auroc))\n",
    "    print('AUPR:  \\t{:.2f}'.format(100 * aupr))\n",
    "\n",
    "\n",
    "def print_measures_with_std(aurocs, auprs, fprs, method_name='Ours', recall_level=recall_level_default):\n",
    "    print('\\t\\t\\t' + method_name)\n",
    "    print('FPR{:d}:\\t{:.2f}\\t+/- {:.2f}'.format(int(100 * recall_level), 100 * np.mean(fprs), 100 * np.std(fprs)))\n",
    "    print('AUROC: \\t{:.2f}\\t+/- {:.2f}'.format(100 * np.mean(aurocs), 100 * np.std(aurocs)))\n",
    "    print('AUPR:  \\t{:.2f}\\t+/- {:.2f}'.format(100 * np.mean(auprs), 100 * np.std(auprs)))\n",
    "\n",
    "\n",
    "def get_and_print_results(out_score, in_score, num_to_avg=1):\n",
    "\n",
    "    aurocs, auprs, fprs = [], [], []\n",
    "    #for _ in range(num_to_avg):\n",
    "    #    out_score = get_ood_scores(ood_loader)\n",
    "    measures = get_measures(out_score, in_score)\n",
    "    aurocs.append(measures[0]); auprs.append(measures[1]); fprs.append(measures[2])\n",
    "\n",
    "    auroc = np.mean(aurocs); aupr = np.mean(auprs); fpr = np.mean(fprs)\n",
    "    #auroc_list.append(auroc); aupr_list.append(aupr); fpr_list.append(fpr)\n",
    "\n",
    "    #if num_to_avg >= 5:\n",
    "    #    print_measures_with_std(aurocs, auprs, fprs, method_name='Ours')\n",
    "    #else:\n",
    "    #    print_measures(auroc, aupr, fpr, method_name='Ours')\n",
    "    return auroc, aupr, fpr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://github.com/hendrycks/natural-adv-examples/blob/master/eval_many_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pretrainedmodels in /home/as14770/.local/lib/python3.9/site-packages (0.7.4)\n",
      "Requirement already satisfied: tqdm in /ext3/miniconda3/lib/python3.9/site-packages (from pretrainedmodels) (4.62.1)\n",
      "Requirement already satisfied: torchvision in /ext3/miniconda3/lib/python3.9/site-packages (from pretrainedmodels) (0.9.0+cu111)\n",
      "Requirement already satisfied: munch in /home/as14770/.local/lib/python3.9/site-packages (from pretrainedmodels) (2.5.0)\n",
      "Requirement already satisfied: torch in /ext3/miniconda3/lib/python3.9/site-packages (from pretrainedmodels) (1.8.0+cu111)\n",
      "Requirement already satisfied: six in /ext3/miniconda3/lib/python3.9/site-packages (from munch->pretrainedmodels) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in /ext3/miniconda3/lib/python3.9/site-packages (from torch->pretrainedmodels) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /ext3/miniconda3/lib/python3.9/site-packages (from torch->pretrainedmodels) (1.21.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /ext3/miniconda3/lib/python3.9/site-packages (from torchvision->pretrainedmodels) (8.3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm==0.3.2 in /home/as14770/.local/lib/python3.9/site-packages (0.3.2)\n",
      "Requirement already satisfied: torch>=1.0 in /ext3/miniconda3/lib/python3.9/site-packages (from timm==0.3.2) (1.8.0+cu111)\n",
      "Requirement already satisfied: torchvision in /ext3/miniconda3/lib/python3.9/site-packages (from timm==0.3.2) (0.9.0+cu111)\n",
      "Requirement already satisfied: numpy in /ext3/miniconda3/lib/python3.9/site-packages (from torch>=1.0->timm==0.3.2) (1.21.2)\n",
      "Requirement already satisfied: typing-extensions in /ext3/miniconda3/lib/python3.9/site-packages (from torch>=1.0->timm==0.3.2) (3.10.0.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /ext3/miniconda3/lib/python3.9/site-packages (from torchvision->timm==0.3.2) (8.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t85.43\n",
      "AUROC: \t50.74\n",
      "AUPR:  \t15.44\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "squeezenet1_1 \n",
      "\n",
      "ImageNet-O Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tMSP\n",
      "FPR95:\t86.66\n",
      "AUROC: \t49.95\n",
      "AUPR:  \t15.31\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t78.09\n",
      "AUROC: \t55.26\n",
      "AUPR:  \t16.58\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t77.89\n",
      "AUROC: \t55.78\n",
      "AUPR:  \t16.80\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19_bn \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t78.27\n",
      "AUROC: \t55.43\n",
      "AUPR:  \t16.57\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet121 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t79.10\n",
      "AUROC: \t54.08\n",
      "AUPR:  \t16.11\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t81.34\n",
      "AUROC: \t41.62\n",
      "AUPR:  \t13.24\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet101 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t75.11\n",
      "AUROC: \t57.37\n",
      "AUPR:  \t17.20\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet152 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t75.92\n",
      "AUROC: \t59.36\n",
      "AUPR:  \t18.00\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wide_resnet50_2 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t77.67\n",
      "AUROC: \t58.85\n",
      "AUPR:  \t17.84\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_32x8d \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t75.35\n",
      "AUROC: \t64.07\n",
      "AUPR:  \t20.51\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext50_32x4d \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t78.57\n",
      "AUROC: \t58.15\n",
      "AUPR:  \t17.60\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth\" to /scratch/as14770/CV-FinalProject/.cvfpmodels/checkpoints/ig_resnext101_32x8-c38310e5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d1dea0fff04c20bb0ecc0861fe5cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/340M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_32x8d_wsl \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t60.82\n",
      "AUROC: \t77.54\n",
      "AUPR:  \t36.75\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth\" to /scratch/as14770/CV-FinalProject/.cvfpmodels/checkpoints/ig_resnext101_32x16-c6f796b0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457ecb173a9e4054b494edadb3dcf2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/741M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_32x16d_wsl \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t60.79\n",
      "AUROC: \t80.32\n",
      "AUPR:  \t42.43\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth\" to /scratch/as14770/CV-FinalProject/.cvfpmodels/checkpoints/ig_resnext101_32x32-e4b90b00.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266492f894d2443284c63564a13345a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_32x32d_wsl \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t53.96\n",
      "AUROC: \t83.63\n",
      "AUPR:  \t46.70\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dpn68 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t77.94\n",
      "AUROC: \t58.41\n",
      "AUPR:  \t17.78\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dpn98 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t75.86\n",
      "AUROC: \t64.58\n",
      "AUPR:  \t21.10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "se_resnet101 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t91.37\n",
      "AUROC: \t56.70\n",
      "AUPR:  \t17.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "se_resnet152 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t91.30\n",
      "AUROC: \t58.26\n",
      "AUPR:  \t18.65\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "resnext101_32x4d \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t76.35\n",
      "AUROC: \t62.31\n",
      "AUPR:  \t19.60\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "se_resnext101_32x4d \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t93.34\n",
      "AUROC: \t60.69\n",
      "AUPR:  \t20.11\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/deit/archive/main.zip\" to /scratch/as14770/CV-FinalProject/.cvfpmodels/main.zip\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /scratch/as14770/CV-FinalProject/.cvfpmodels/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082a15b8ad2b4903b972ef578c62e5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/330M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deit_base_patch16_224 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t86.21\n",
      "AUROC: \t66.68\n",
      "AUPR:  \t24.58\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/facebookresearch_deit_main\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth\" to /scratch/as14770/CV-FinalProject/.cvfpmodels/checkpoints/deit_small_patch16_224-cd65a155.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db16790f18e450ea4c7fc6d21bcd9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/84.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deit_small_patch16_224 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t90.57\n",
      "AUROC: \t62.26\n",
      "AUPR:  \t20.91\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /scratch/as14770/CV-FinalProject/.cvfpmodels/facebookresearch_deit_main\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\" to /scratch/as14770/CV-FinalProject/.cvfpmodels/checkpoints/deit_tiny_patch16_224-a1311bcf.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d9b26f71f14d75b8a195c8d46249ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/21.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deit_tiny_patch16_224 \n",
      "\n",
      "ImageNet-O Results\n",
      "\t\t\tMSP\n",
      "FPR95:\t85.83\n",
      "AUROC: \t56.49\n",
      "AUPR:  \t17.43\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import calibration_tools\n",
    "!pip install pretrainedmodels\n",
    "!pip install timm==0.3.2\n",
    "# timm is needed for deit models\n",
    "import timm\n",
    "# assert timm.__version__ == \"0.3.2\"\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/as14770/.local/lib/python3.9/site-packages')\n",
    "import pretrainedmodels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.transforms.functional as trnF\n",
    "import torchvision.models as models\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#PATH_TO_IMAGENET_A = \"./imagenet-a\"\n",
    "PATH_TO_IMAGENET_O = \"/scratch/as14770/CV-FinalProject/DATA/imagenet-o\"\n",
    "PATH_TO_IMAGENET_VAL = \"/scratch/as14770/CV-FinalProject/DATA/imagenet1k-val\"\n",
    "TORCH_HOME_DIR = \"/scratch/as14770/CV-FinalProject/.cvfpmodels/\"\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "test_transform = trn.Compose(\n",
    "    [trn.Resize(256), trn.CenterCrop(224), trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "all_wnids = ['n01440764', 'n01443537', 'n01484850', 'n01491361', 'n01494475', 'n01496331', 'n01498041', 'n01514668', 'n01514859', 'n01518878', 'n01530575', 'n01531178', 'n01532829', 'n01534433', 'n01537544', 'n01558993', 'n01560419', 'n01580077', 'n01582220', 'n01592084', 'n01601694', 'n01608432', 'n01614925', 'n01616318', 'n01622779', 'n01629819', 'n01630670', 'n01631663', 'n01632458', 'n01632777', 'n01641577', 'n01644373', 'n01644900', 'n01664065', 'n01665541', 'n01667114', 'n01667778', 'n01669191', 'n01675722', 'n01677366', 'n01682714', 'n01685808', 'n01687978', 'n01688243', 'n01689811', 'n01692333', 'n01693334', 'n01694178', 'n01695060', 'n01697457', 'n01698640', 'n01704323', 'n01728572', 'n01728920', 'n01729322', 'n01729977', 'n01734418', 'n01735189', 'n01737021', 'n01739381', 'n01740131', 'n01742172', 'n01744401', 'n01748264', 'n01749939', 'n01751748', 'n01753488', 'n01755581', 'n01756291', 'n01768244', 'n01770081', 'n01770393', 'n01773157', 'n01773549', 'n01773797', 'n01774384', 'n01774750', 'n01775062', 'n01776313', 'n01784675', 'n01795545', 'n01796340', 'n01797886', 'n01798484', 'n01806143', 'n01806567', 'n01807496', 'n01817953', 'n01818515', 'n01819313', 'n01820546', 'n01824575', 'n01828970', 'n01829413', 'n01833805', 'n01843065', 'n01843383', 'n01847000', 'n01855032', 'n01855672', 'n01860187', 'n01871265', 'n01872401', 'n01873310', 'n01877812', 'n01882714', 'n01883070', 'n01910747', 'n01914609', 'n01917289', 'n01924916', 'n01930112', 'n01943899', 'n01944390', 'n01945685', 'n01950731', 'n01955084', 'n01968897', 'n01978287', 'n01978455', 'n01980166', 'n01981276', 'n01983481', 'n01984695', 'n01985128', 'n01986214', 'n01990800', 'n02002556', 'n02002724', 'n02006656', 'n02007558', 'n02009229', 'n02009912', 'n02011460', 'n02012849', 'n02013706', 'n02017213', 'n02018207', 'n02018795', 'n02025239', 'n02027492', 'n02028035', 'n02033041', 'n02037110', 'n02051845', 'n02056570', 'n02058221', 'n02066245', 'n02071294', 'n02074367', 'n02077923', 'n02085620', 'n02085782', 'n02085936', 'n02086079', 'n02086240', 'n02086646', 'n02086910', 'n02087046', 'n02087394', 'n02088094', 'n02088238', 'n02088364', 'n02088466', 'n02088632', 'n02089078', 'n02089867', 'n02089973', 'n02090379', 'n02090622', 'n02090721', 'n02091032', 'n02091134', 'n02091244', 'n02091467', 'n02091635', 'n02091831', 'n02092002', 'n02092339', 'n02093256', 'n02093428', 'n02093647', 'n02093754', 'n02093859', 'n02093991', 'n02094114', 'n02094258', 'n02094433', 'n02095314', 'n02095570', 'n02095889', 'n02096051', 'n02096177', 'n02096294', 'n02096437', 'n02096585', 'n02097047', 'n02097130', 'n02097209', 'n02097298', 'n02097474', 'n02097658', 'n02098105', 'n02098286', 'n02098413', 'n02099267', 'n02099429', 'n02099601', 'n02099712', 'n02099849', 'n02100236', 'n02100583', 'n02100735', 'n02100877', 'n02101006', 'n02101388', 'n02101556', 'n02102040', 'n02102177', 'n02102318', 'n02102480', 'n02102973', 'n02104029', 'n02104365', 'n02105056', 'n02105162', 'n02105251', 'n02105412', 'n02105505', 'n02105641', 'n02105855', 'n02106030', 'n02106166', 'n02106382', 'n02106550', 'n02106662', 'n02107142', 'n02107312', 'n02107574', 'n02107683', 'n02107908', 'n02108000', 'n02108089', 'n02108422', 'n02108551', 'n02108915', 'n02109047', 'n02109525', 'n02109961', 'n02110063', 'n02110185', 'n02110341', 'n02110627', 'n02110806', 'n02110958', 'n02111129', 'n02111277', 'n02111500', 'n02111889', 'n02112018', 'n02112137', 'n02112350', 'n02112706', 'n02113023', 'n02113186', 'n02113624', 'n02113712', 'n02113799', 'n02113978', 'n02114367', 'n02114548', 'n02114712', 'n02114855', 'n02115641', 'n02115913', 'n02116738', 'n02117135', 'n02119022', 'n02119789', 'n02120079', 'n02120505', 'n02123045', 'n02123159', 'n02123394', 'n02123597', 'n02124075', 'n02125311', 'n02127052', 'n02128385', 'n02128757', 'n02128925', 'n02129165', 'n02129604', 'n02130308', 'n02132136', 'n02133161', 'n02134084', 'n02134418', 'n02137549', 'n02138441', 'n02165105', 'n02165456', 'n02167151', 'n02168699', 'n02169497', 'n02172182', 'n02174001', 'n02177972', 'n02190166', 'n02206856', 'n02219486', 'n02226429', 'n02229544', 'n02231487', 'n02233338', 'n02236044', 'n02256656', 'n02259212', 'n02264363', 'n02268443', 'n02268853', 'n02276258', 'n02277742', 'n02279972', 'n02280649', 'n02281406', 'n02281787', 'n02317335', 'n02319095', 'n02321529', 'n02325366', 'n02326432', 'n02328150', 'n02342885', 'n02346627', 'n02356798', 'n02361337', 'n02363005', 'n02364673', 'n02389026', 'n02391049', 'n02395406', 'n02396427', 'n02397096', 'n02398521', 'n02403003', 'n02408429', 'n02410509', 'n02412080', 'n02415577', 'n02417914', 'n02422106', 'n02422699', 'n02423022', 'n02437312', 'n02437616', 'n02441942', 'n02442845', 'n02443114', 'n02443484', 'n02444819', 'n02445715', 'n02447366', 'n02454379', 'n02457408', 'n02480495', 'n02480855', 'n02481823', 'n02483362', 'n02483708', 'n02484975', 'n02486261', 'n02486410', 'n02487347', 'n02488291', 'n02488702', 'n02489166', 'n02490219', 'n02492035', 'n02492660', 'n02493509', 'n02493793', 'n02494079', 'n02497673', 'n02500267', 'n02504013', 'n02504458', 'n02509815', 'n02510455', 'n02514041', 'n02526121', 'n02536864', 'n02606052', 'n02607072', 'n02640242', 'n02641379', 'n02643566', 'n02655020', 'n02666196', 'n02667093', 'n02669723', 'n02672831', 'n02676566', 'n02687172', 'n02690373', 'n02692877', 'n02699494', 'n02701002', 'n02704792', 'n02708093', 'n02727426', 'n02730930', 'n02747177', 'n02749479', 'n02769748', 'n02776631', 'n02777292', 'n02782093', 'n02783161', 'n02786058', 'n02787622', 'n02788148', 'n02790996', 'n02791124', 'n02791270', 'n02793495', 'n02794156', 'n02795169', 'n02797295', 'n02799071', 'n02802426', 'n02804414', 'n02804610', 'n02807133', 'n02808304', 'n02808440', 'n02814533', 'n02814860', 'n02815834', 'n02817516', 'n02823428', 'n02823750', 'n02825657', 'n02834397', 'n02835271', 'n02837789', 'n02840245', 'n02841315', 'n02843684', 'n02859443', 'n02860847', 'n02865351', 'n02869837', 'n02870880', 'n02871525', 'n02877765', 'n02879718', 'n02883205', 'n02892201', 'n02892767', 'n02894605', 'n02895154', 'n02906734', 'n02909870', 'n02910353', 'n02916936', 'n02917067', 'n02927161', 'n02930766', 'n02939185', 'n02948072', 'n02950826', 'n02951358', 'n02951585', 'n02963159', 'n02965783', 'n02966193', 'n02966687', 'n02971356', 'n02974003', 'n02977058', 'n02978881', 'n02979186', 'n02980441', 'n02981792', 'n02988304', 'n02992211', 'n02992529', 'n02999410', 'n03000134', 'n03000247', 'n03000684', 'n03014705', 'n03016953', 'n03017168', 'n03018349', 'n03026506', 'n03028079', 'n03032252', 'n03041632', 'n03042490', 'n03045698', 'n03047690', 'n03062245', 'n03063599', 'n03063689', 'n03065424', 'n03075370', 'n03085013', 'n03089624', 'n03095699', 'n03100240', 'n03109150', 'n03110669', 'n03124043', 'n03124170', 'n03125729', 'n03126707', 'n03127747', 'n03127925', 'n03131574', 'n03133878', 'n03134739', 'n03141823', 'n03146219', 'n03160309', 'n03179701', 'n03180011', 'n03187595', 'n03188531', 'n03196217', 'n03197337', 'n03201208', 'n03207743', 'n03207941', 'n03208938', 'n03216828', 'n03218198', 'n03220513', 'n03223299', 'n03240683', 'n03249569', 'n03250847', 'n03255030', 'n03259280', 'n03271574', 'n03272010', 'n03272562', 'n03290653', 'n03291819', 'n03297495', 'n03314780', 'n03325584', 'n03337140', 'n03344393', 'n03345487', 'n03347037', 'n03355925', 'n03372029', 'n03376595', 'n03379051', 'n03384352', 'n03388043', 'n03388183', 'n03388549', 'n03393912', 'n03394916', 'n03400231', 'n03404251', 'n03417042', 'n03424325', 'n03425413', 'n03443371', 'n03444034', 'n03445777', 'n03445924', 'n03447447', 'n03447721', 'n03450230', 'n03452741', 'n03457902', 'n03459775', 'n03461385', 'n03467068', 'n03476684', 'n03476991', 'n03478589', 'n03481172', 'n03482405', 'n03483316', 'n03485407', 'n03485794', 'n03492542', 'n03494278', 'n03495258', 'n03496892', 'n03498962', 'n03527444', 'n03529860', 'n03530642', 'n03532672', 'n03534580', 'n03535780', 'n03538406', 'n03544143', 'n03584254', 'n03584829', 'n03590841', 'n03594734', 'n03594945', 'n03595614', 'n03598930', 'n03599486', 'n03602883', 'n03617480', 'n03623198', 'n03627232', 'n03630383', 'n03633091', 'n03637318', 'n03642806', 'n03649909', 'n03657121', 'n03658185', 'n03661043', 'n03662601', 'n03666591', 'n03670208', 'n03673027', 'n03676483', 'n03680355', 'n03690938', 'n03691459', 'n03692522', 'n03697007', 'n03706229', 'n03709823', 'n03710193', 'n03710637', 'n03710721', 'n03717622', 'n03720891', 'n03721384', 'n03724870', 'n03729826', 'n03733131', 'n03733281', 'n03733805', 'n03742115', 'n03743016', 'n03759954', 'n03761084', 'n03763968', 'n03764736', 'n03769881', 'n03770439', 'n03770679', 'n03773504', 'n03775071', 'n03775546', 'n03776460', 'n03777568', 'n03777754', 'n03781244', 'n03782006', 'n03785016', 'n03786901', 'n03787032', 'n03788195', 'n03788365', 'n03791053', 'n03792782', 'n03792972', 'n03793489', 'n03794056', 'n03796401', 'n03803284', 'n03804744', 'n03814639', 'n03814906', 'n03825788', 'n03832673', 'n03837869', 'n03838899', 'n03840681', 'n03841143', 'n03843555', 'n03854065', 'n03857828', 'n03866082', 'n03868242', 'n03868863', 'n03871628', 'n03873416', 'n03874293', 'n03874599', 'n03876231', 'n03877472', 'n03877845', 'n03884397', 'n03887697', 'n03888257', 'n03888605', 'n03891251', 'n03891332', 'n03895866', 'n03899768', 'n03902125', 'n03903868', 'n03908618', 'n03908714', 'n03916031', 'n03920288', 'n03924679', 'n03929660', 'n03929855', 'n03930313', 'n03930630', 'n03933933', 'n03935335', 'n03937543', 'n03938244', 'n03942813', 'n03944341', 'n03947888', 'n03950228', 'n03954731', 'n03956157', 'n03958227', 'n03961711', 'n03967562', 'n03970156', 'n03976467', 'n03976657', 'n03977966', 'n03980874', 'n03982430', 'n03983396', 'n03991062', 'n03992509', 'n03995372', 'n03998194', 'n04004767', 'n04005630', 'n04008634', 'n04009552', 'n04019541', 'n04023962', 'n04026417', 'n04033901', 'n04033995', 'n04037443', 'n04039381', 'n04040759', 'n04041544', 'n04044716', 'n04049303', 'n04065272', 'n04067472', 'n04069434', 'n04070727', 'n04074963', 'n04081281', 'n04086273', 'n04090263', 'n04099969', 'n04111531', 'n04116512', 'n04118538', 'n04118776', 'n04120489', 'n04125021', 'n04127249', 'n04131690', 'n04133789', 'n04136333', 'n04141076', 'n04141327', 'n04141975', 'n04146614', 'n04147183', 'n04149813', 'n04152593', 'n04153751', 'n04154565', 'n04162706', 'n04179913', 'n04192698', 'n04200800', 'n04201297', 'n04204238', 'n04204347', 'n04208210', 'n04209133', 'n04209239', 'n04228054', 'n04229816', 'n04235860', 'n04238763', 'n04239074', 'n04243546', 'n04251144', 'n04252077', 'n04252225', 'n04254120', 'n04254680', 'n04254777', 'n04258138', 'n04259630', 'n04263257', 'n04264628', 'n04265275', 'n04266014', 'n04270147', 'n04273569', 'n04275548', 'n04277352', 'n04285008', 'n04286575', 'n04296562', 'n04310018', 'n04311004', 'n04311174', 'n04317175', 'n04325704', 'n04326547', 'n04328186', 'n04330267', 'n04332243', 'n04335435', 'n04336792', 'n04344873', 'n04346328', 'n04347754', 'n04350905', 'n04355338', 'n04355933', 'n04356056', 'n04357314', 'n04366367', 'n04367480', 'n04370456', 'n04371430', 'n04371774', 'n04372370', 'n04376876', 'n04380533', 'n04389033', 'n04392985', 'n04398044', 'n04399382', 'n04404412', 'n04409515', 'n04417672', 'n04418357', 'n04423845', 'n04428191', 'n04429376', 'n04435653', 'n04442312', 'n04443257', 'n04447861', 'n04456115', 'n04458633', 'n04461696', 'n04462240', 'n04465501', 'n04467665', 'n04476259', 'n04479046', 'n04482393', 'n04483307', 'n04485082', 'n04486054', 'n04487081', 'n04487394', 'n04493381', 'n04501370', 'n04505470', 'n04507155', 'n04509417', 'n04515003', 'n04517823', 'n04522168', 'n04523525', 'n04525038', 'n04525305', 'n04532106', 'n04532670', 'n04536866', 'n04540053', 'n04542943', 'n04548280', 'n04548362', 'n04550184', 'n04552348', 'n04553703', 'n04554684', 'n04557648', 'n04560804', 'n04562935', 'n04579145', 'n04579432', 'n04584207', 'n04589890', 'n04590129', 'n04591157', 'n04591713', 'n04592741', 'n04596742', 'n04597913', 'n04599235', 'n04604644', 'n04606251', 'n04612504', 'n04613696', 'n06359193', 'n06596364', 'n06785654', 'n06794110', 'n06874185', 'n07248320', 'n07565083', 'n07579787', 'n07583066', 'n07584110', 'n07590611', 'n07613480', 'n07614500', 'n07615774', 'n07684084', 'n07693725', 'n07695742', 'n07697313', 'n07697537', 'n07711569', 'n07714571', 'n07714990', 'n07715103', 'n07716358', 'n07716906', 'n07717410', 'n07717556', 'n07718472', 'n07718747', 'n07720875', 'n07730033', 'n07734744', 'n07742313', 'n07745940', 'n07747607', 'n07749582', 'n07753113', 'n07753275', 'n07753592', 'n07754684', 'n07760859', 'n07768694', 'n07802026', 'n07831146', 'n07836838', 'n07860988', 'n07871810', 'n07873807', 'n07875152', 'n07880968', 'n07892512', 'n07920052', 'n07930864', 'n07932039', 'n09193705', 'n09229709', 'n09246464', 'n09256479', 'n09288635', 'n09332890', 'n09399592', 'n09421951', 'n09428293', 'n09468604', 'n09472597', 'n09835506', 'n10148035', 'n10565667', 'n11879895', 'n11939491', 'n12057211', 'n12144580', 'n12267677', 'n12620546', 'n12768682', 'n12985857', 'n12998815', 'n13037406', 'n13040303', 'n13044778', 'n13052670', 'n13054560', 'n13133613', 'n15075141']\n",
    "\n",
    "# imagenet_a_wnids = ['n01498041', 'n01531178', 'n01534433', 'n01558993', 'n01580077', 'n01614925', 'n01616318', 'n01631663', 'n01641577', 'n01669191', 'n01677366', 'n01687978', 'n01694178', 'n01698640', 'n01735189', 'n01770081', 'n01770393', 'n01774750', 'n01784675', 'n01819313', 'n01820546', 'n01833805', 'n01843383', 'n01847000', 'n01855672', 'n01882714', 'n01910747', 'n01914609', 'n01924916', 'n01944390', 'n01985128', 'n01986214', 'n02007558', 'n02009912', 'n02037110', 'n02051845', 'n02077923', 'n02085620', 'n02099601', 'n02106550', 'n02106662', 'n02110958', 'n02119022', 'n02123394', 'n02127052', 'n02129165', 'n02133161', 'n02137549', 'n02165456', 'n02174001', 'n02177972', 'n02190166', 'n02206856', 'n02219486', 'n02226429', 'n02231487', 'n02233338', 'n02236044', 'n02259212', 'n02268443', 'n02279972', 'n02280649', 'n02281787', 'n02317335', 'n02325366', 'n02346627', 'n02356798', 'n02361337', 'n02410509', 'n02445715', 'n02454379', 'n02486410', 'n02492035', 'n02504458', 'n02655020', 'n02669723', 'n02672831', 'n02676566', 'n02690373', 'n02701002', 'n02730930', 'n02777292', 'n02782093', 'n02787622', 'n02793495', 'n02797295', 'n02802426', 'n02814860', 'n02815834', 'n02837789', 'n02879718', 'n02883205', 'n02895154', 'n02906734', 'n02948072', 'n02951358', 'n02980441', 'n02992211', 'n02999410', 'n03014705', 'n03026506', 'n03124043', 'n03125729', 'n03187595', 'n03196217', 'n03223299', 'n03250847', 'n03255030', 'n03291819', 'n03325584', 'n03355925', 'n03384352', 'n03388043', 'n03417042', 'n03443371', 'n03444034', 'n03445924', 'n03452741', 'n03483316', 'n03584829', 'n03590841', 'n03594945', 'n03617480', 'n03666591', 'n03670208', 'n03717622', 'n03720891', 'n03721384', 'n03724870', 'n03775071', 'n03788195', 'n03804744', 'n03837869', 'n03840681', 'n03854065', 'n03888257', 'n03891332', 'n03935335', 'n03982430', 'n04019541', 'n04033901', 'n04039381', 'n04067472', 'n04086273', 'n04099969', 'n04118538', 'n04131690', 'n04133789', 'n04141076', 'n04146614', 'n04147183', 'n04179913', 'n04208210', 'n04235860', 'n04252077', 'n04252225', 'n04254120', 'n04270147', 'n04275548', 'n04310018', 'n04317175', 'n04344873', 'n04347754', 'n04355338', 'n04366367', 'n04376876', 'n04389033', 'n04399382', 'n04442312', 'n04456115', 'n04482393', 'n04507155', 'n04509417', 'n04532670', 'n04540053', 'n04554684', 'n04562935', 'n04591713', 'n04606251', 'n07583066', 'n07695742', 'n07697313', 'n07697537', 'n07714990', 'n07718472', 'n07720875', 'n07734744', 'n07749582', 'n07753592', 'n07760859', 'n07768694', 'n07831146', 'n09229709', 'n09246464', 'n09472597', 'n09835506', 'n11879895', 'n12057211', 'n12144580', 'n12267677']\n",
    "\n",
    "# imagenet_a_mask = [wnid in set(imagenet_a_wnids) for wnid in all_wnids]\n",
    "\n",
    "imagenet_o_wnids = ['n01443537', 'n01704323', 'n01770081', 'n01784675', 'n01819313', 'n01820546', 'n01910747', 'n01917289', 'n01968897', 'n02074367', 'n02317335', 'n02319095', 'n02395406', 'n02454379', 'n02606052', 'n02655020', 'n02666196', 'n02672831', 'n02730930', 'n02777292', 'n02783161', 'n02786058', 'n02787622', 'n02791270', 'n02808304', 'n02817516', 'n02841315', 'n02865351', 'n02877765', 'n02892767', 'n02906734', 'n02910353', 'n02916936', 'n02948072', 'n02965783', 'n03000134', 'n03000684', 'n03017168', 'n03026506', 'n03032252', 'n03075370', 'n03109150', 'n03126707', 'n03134739', 'n03160309', 'n03196217', 'n03207743', 'n03218198', 'n03223299', 'n03240683', 'n03271574', 'n03291819', 'n03297495', 'n03314780', 'n03325584', 'n03344393', 'n03347037', 'n03372029', 'n03376595', 'n03388043', 'n03388183', 'n03400231', 'n03445777', 'n03457902', 'n03467068', 'n03482405', 'n03483316', 'n03494278', 'n03530642', 'n03544143', 'n03584829', 'n03590841', 'n03598930', 'n03602883', 'n03649909', 'n03661043', 'n03666591', 'n03676483', 'n03692522', 'n03706229', 'n03717622', 'n03720891', 'n03721384', 'n03724870', 'n03729826', 'n03733131', 'n03733281', 'n03742115', 'n03786901', 'n03788365', 'n03794056', 'n03804744', 'n03814639', 'n03814906', 'n03825788', 'n03840681', 'n03843555', 'n03854065', 'n03857828', 'n03868863', 'n03874293', 'n03884397', 'n03891251', 'n03908714', 'n03920288', 'n03929660', 'n03930313', 'n03937543', 'n03942813', 'n03944341', 'n03961711', 'n03970156', 'n03982430', 'n03991062', 'n03995372', 'n03998194', 'n04005630', 'n04023962', 'n04033901', 'n04040759', 'n04067472', 'n04074963', 'n04116512', 'n04118776', 'n04125021', 'n04127249', 'n04131690', 'n04141975', 'n04153751', 'n04154565', 'n04201297', 'n04204347', 'n04209133', 'n04209239', 'n04228054', 'n04235860', 'n04243546', 'n04252077', 'n04254120', 'n04258138', 'n04265275', 'n04270147', 'n04275548', 'n04330267', 'n04332243', 'n04336792', 'n04347754', 'n04371430', 'n04371774', 'n04372370', 'n04376876', 'n04409515', 'n04417672', 'n04418357', 'n04423845', 'n04429376', 'n04435653', 'n04442312', 'n04482393', 'n04501370', 'n04507155', 'n04525305', 'n04542943', 'n04554684', 'n04557648', 'n04562935', 'n04579432', 'n04591157', 'n04597913', 'n04599235', 'n06785654', 'n06874185', 'n07615774', 'n07693725', 'n07695742', 'n07697537', 'n07711569', 'n07714990', 'n07715103', 'n07716358', 'n07717410', 'n07718472', 'n07720875', 'n07742313', 'n07745940', 'n07747607', 'n07749582', 'n07753275', 'n07753592', 'n07754684', 'n07768694', 'n07836838', 'n07871810', 'n07873807', 'n07880968', 'n09229709', 'n09472597', 'n12144580', 'n12267677', 'n13052670']\n",
    "\n",
    "imagenet_o_mask = [wnid in set(imagenet_o_wnids) for wnid in all_wnids]\n",
    "\n",
    "\n",
    "# naes = dset.ImageFolder(root=PATH_TO_IMAGENET_A, transform=test_transform)\n",
    "# nae_loader = torch.utils.data.DataLoader(naes, batch_size=64, shuffle=False,\n",
    "#                                          num_workers=4, pin_memory=True)\n",
    "\n",
    "noes = dset.ImageFolder(root=PATH_TO_IMAGENET_O, transform=test_transform)\n",
    "noe_loader = torch.utils.data.DataLoader(noes, batch_size=64, shuffle=False,\n",
    "                                         num_workers=4, pin_memory=True)\n",
    "\n",
    "imagenet_o_folder = \"/scratch/as14770/CV-FinalProject/imagenet-o-symlink/\"\n",
    "\n",
    "def create_symlinks_to_imagenet(imagenet_folder, folder_to_scan):\n",
    "  if not os.path.exists(imagenet_folder):\n",
    "    os.makedirs(imagenet_folder)\n",
    "    folders_of_interest = os.listdir(folder_to_scan)\n",
    "    path_prefix = PATH_TO_IMAGENET_VAL+\"/val/\" \n",
    "    for folder in folders_of_interest:\n",
    "        os.symlink(path_prefix + folder, imagenet_folder+folder, target_is_directory=True)\n",
    "\n",
    "create_symlinks_to_imagenet(imagenet_o_folder, PATH_TO_IMAGENET_O)\n",
    "\n",
    "val_examples_imagenet_o = dset.ImageFolder(root=imagenet_o_folder, transform=test_transform)\n",
    "val_loader_imagenet_o = torch.utils.data.DataLoader(val_examples_imagenet_o, batch_size=128, shuffle=False,\n",
    "                                         num_workers=4, pin_memory=True)\n",
    "\n",
    "val_imagenet = dset.ImageNet(root=PATH_TO_IMAGENET_VAL, split = 'val', transform=test_transform)\n",
    "val_imagenet_loader = torch.utils.data.DataLoader(val_imagenet, batch_size=128, shuffle=False,\n",
    "                                         num_workers=4, pin_memory=True)\n",
    "\n",
    "concat = lambda x: np.concatenate(x, axis=0)\n",
    "to_np = lambda x: x.data.to('cpu').numpy()\n",
    "\n",
    "def get_predictions(loader, net=None, mask=None):\n",
    "    confidence = []\n",
    "    correct = []\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = net(data)[:,mask]\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1)[1]\n",
    "            num_correct += pred.eq(target.data).sum().item()\n",
    "\n",
    "            confidence.extend(to_np(F.softmax(output, dim=1).max(1)[0]).squeeze().tolist())\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct.extend(pred.eq(target).to('cpu').numpy().squeeze().tolist())\n",
    "\n",
    "    return np.array(confidence), np.array(correct), num_correct\n",
    "\n",
    "\n",
    "# def get_imagenet_a_results(loader, net, mask):\n",
    "#     confidence, correct, num_correct = get_predictions(loader, net, mask)\n",
    "#     acc = num_correct / len(loader.dataset)\n",
    "#     print('Accuracy (%):', round(100*acc, 4))\n",
    "#     calibration_tools.show_calibration_results(confidence, correct)\n",
    "\n",
    "\n",
    "def get_imagenet_o_results(in_loader, out_loader, net, mask):\n",
    "    confidence_in, correct, num_correct = get_predictions(in_loader, net=net, mask=mask)\n",
    "    in_score = -confidence_in\n",
    "    confidence_out, correct_out, num_correct_out = get_predictions(out_loader, net=net, mask=mask)\n",
    "    out_score = -confidence_out\n",
    "\n",
    "    aurocs, auprs, fprs = [], [], []\n",
    "    measures = get_measures(out_score, in_score)\n",
    "    aurocs = measures[0]; auprs = measures[1]; fprs = measures[2]\n",
    "\n",
    "    print_measures_old(aurocs, auprs, fprs, method_name='MSP')\n",
    "\n",
    "    # acc = num_correct_out / len(nae_loader.dataset)\n",
    "    # print('Out Dist Accuracy (%):', round(100*acc, 4))\n",
    "\n",
    "os.environ[\"TORCH_HOME\"] = TORCH_HOME_DIR\n",
    "#print(os.environ[\"TORCH_HOME\"])\n",
    "torch.hub.set_dir(TORCH_HOME_DIR)\n",
    "models_to_test = [\n",
    "    (\"pytorch/vision\", \"alexnet\"),\n",
    "    (\"pytorch/vision\", \"squeezenet1_1\"),\n",
    "    (\"pytorch/vision\", \"vgg16\"),\n",
    "    (\"pytorch/vision\", \"vgg19\"),\n",
    "    ('pytorch/vision', \"vgg19_bn\"),\n",
    "    ('pytorch/vision', \"densenet121\"),\n",
    "    ('pytorch/vision', \"resnet50\"),\n",
    "    ('pytorch/vision', \"resnet101\"),\n",
    "    ('pytorch/vision', \"resnet152\"),\n",
    "    ('pytorch/vision', \"wide_resnet50_2\"),\n",
    "    ('pytorch/vision', \"resnext101_32x8d\"),\n",
    "    ('pytorch/vision', \"resnext50_32x4d\"),\n",
    "    ('facebookresearch/WSL-Images', \"resnext101_32x8d_wsl\"),\n",
    "    ('facebookresearch/WSL-Images', \"resnext101_32x16d_wsl\"),\n",
    "    ('facebookresearch/WSL-Images', \"resnext101_32x32d_wsl\"),\n",
    "    (\"pretrained\", \"dpn68\"),\n",
    "    (\"pretrained\", \"dpn98\"),\n",
    "    (\"pretrained\", \"se_resnet101\"),\n",
    "    (\"pretrained\", \"se_resnet152\"),\n",
    "    (\"pretrained\", \"resnext101_32x4d\"),\n",
    "    (\"pretrained\", \"se_resnext101_32x4d\"),\n",
    "    (\"facebookresearch/deit:main\", \"deit_base_patch16_224\"),\n",
    "    (\"facebookresearch/deit:main\", \"deit_small_patch16_224\"),\n",
    "    (\"facebookresearch/deit:main\", \"deit_tiny_patch16_224\"),\n",
    "]\n",
    "\n",
    "for net_params in models_to_test:\n",
    "    if net_params[0] == \"pytorch/vision\":\n",
    "        net = torch.hub.load('pytorch/vision:v0.10.0', net_params[1], pretrained=True)\n",
    "#         net = models.alexnet(pretrained=True)\n",
    "    elif \"facebookresearch/deit\" in net_params[0]:\n",
    "        net = torch.hub.load(net_params[0], net_params[1], pretrained=True)\n",
    "    elif net_params[0] == \"pretrained\":\n",
    "        net = pretrainedmodels.__dict__[net_params[1]](num_classes=1000, pretrained='imagenet')\n",
    "    else:\n",
    "        net = torch.hub.load('/scratch/as14770/CV-FinalProject/facebookresearch_WSL-Images_master', net_params[1], source='local')\n",
    "    print(net_params[1], '\\n')\n",
    "    net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    \n",
    "    # print(\"ImageNet-A Results\")\n",
    "    # get_imagenet_a_results(nae_loader, net=net, mask=imagenet_a_mask)\n",
    "    # print(\"\\n\")\n",
    "    print(\"ImageNet-O Results\")\n",
    "    get_imagenet_o_results(val_loader_imagenet_o, noe_loader, net=net, mask=imagenet_o_mask)\n",
    "\n",
    "    print(\"\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_pytorch_env",
   "language": "python",
   "name": "my_pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
